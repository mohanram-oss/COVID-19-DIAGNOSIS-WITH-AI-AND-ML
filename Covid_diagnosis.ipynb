{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kpc_Kyn8MUJ1"
   },
   "source": [
    "# **COVID 19 Diagnosis System**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dC9Y08bYQVcl"
   },
   "source": [
    "### **Importing the Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u5j8z4HGV_20"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import random\n",
    "from imutils import paths\n",
    "from tensorflow.keras.applications import VGG16, VGG19\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NVwh4rf4Qdjp"
   },
   "source": [
    "### **Data Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "9kzj0yTiQcd9",
    "outputId": "4f30ae67-bb47-4fcd-d2ee-fd39659325b4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patientid</th>\n",
       "      <th>offset</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>finding</th>\n",
       "      <th>survival</th>\n",
       "      <th>view</th>\n",
       "      <th>modality</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>filename</th>\n",
       "      <th>doi</th>\n",
       "      <th>url</th>\n",
       "      <th>license</th>\n",
       "      <th>clinical notes</th>\n",
       "      <th>other notes</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M</td>\n",
       "      <td>65.0</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>Y</td>\n",
       "      <td>PA</td>\n",
       "      <td>X-ray</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auntminnie-a-2020_01_28_23_51_6665_2020_01_28_...</td>\n",
       "      <td>10.1056/nejmc2001272</td>\n",
       "      <td>https://www.nejm.org/doi/full/10.1056/NEJMc200...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>65.0</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>Y</td>\n",
       "      <td>PA</td>\n",
       "      <td>X-ray</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auntminnie-b-2020_01_28_23_51_6665_2020_01_28_...</td>\n",
       "      <td>10.1056/nejmc2001272</td>\n",
       "      <td>https://www.nejm.org/doi/full/10.1056/NEJMc200...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>M</td>\n",
       "      <td>65.0</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>Y</td>\n",
       "      <td>PA</td>\n",
       "      <td>X-ray</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auntminnie-c-2020_01_28_23_51_6665_2020_01_28_...</td>\n",
       "      <td>10.1056/nejmc2001272</td>\n",
       "      <td>https://www.nejm.org/doi/full/10.1056/NEJMc200...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>M</td>\n",
       "      <td>65.0</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>Y</td>\n",
       "      <td>PA</td>\n",
       "      <td>X-ray</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auntminnie-d-2020_01_28_23_51_6665_2020_01_28_...</td>\n",
       "      <td>10.1056/nejmc2001272</td>\n",
       "      <td>https://www.nejm.org/doi/full/10.1056/NEJMc200...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>52.0</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PA</td>\n",
       "      <td>X-ray</td>\n",
       "      <td>2020</td>\n",
       "      <td>Changhua Christian Hospital, Changhua City, Ta...</td>\n",
       "      <td>nejmc2001573_f1a.jpeg</td>\n",
       "      <td>10.1056/NEJMc2001573</td>\n",
       "      <td>https://www.nejm.org/doi/full/10.1056/NEJMc200...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>diffuse infiltrates in the bilateral lower lungs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patientid  offset  ... other notes  Unnamed: 16\n",
       "0          2     0.0  ...         NaN          NaN\n",
       "1          2     3.0  ...         NaN          NaN\n",
       "2          2     5.0  ...         NaN          NaN\n",
       "3          2     6.0  ...         NaN          NaN\n",
       "4          4     0.0  ...         NaN          NaN\n",
       "\n",
       "[5 rows x 17 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the data about data\n",
    "covid_data = pd.read_csv('metadata.csv')\n",
    "covid_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "OccEtmllRplB",
    "outputId": "32d24024-f935-478b-cff7-b2f130cc5c40"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>finding</th>\n",
       "      <th>view</th>\n",
       "      <th>modality</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>PA</td>\n",
       "      <td>X-ray</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>PA</td>\n",
       "      <td>X-ray</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>PA</td>\n",
       "      <td>X-ray</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>PA</td>\n",
       "      <td>X-ray</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>PA</td>\n",
       "      <td>X-ray</td>\n",
       "      <td>Changhua Christian Hospital, Changhua City, Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>AP Supine</td>\n",
       "      <td>X-ray</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>PA</td>\n",
       "      <td>X-ray</td>\n",
       "      <td>The Royal Melbourne Hospital, Melbourne, Austr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>PA</td>\n",
       "      <td>X-ray</td>\n",
       "      <td>The Royal Melbourne Hospital, Melbourne, Austr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>AP</td>\n",
       "      <td>X-ray</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>PA</td>\n",
       "      <td>X-ray</td>\n",
       "      <td>Laniado Hospital, Netanya, Israel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      finding  ...                                           location\n",
       "0    COVID-19  ...                                                NaN\n",
       "1    COVID-19  ...                                                NaN\n",
       "2    COVID-19  ...                                                NaN\n",
       "3    COVID-19  ...                                                NaN\n",
       "4    COVID-19  ...  Changhua Christian Hospital, Changhua City, Ta...\n",
       "..        ...  ...                                                ...\n",
       "141  COVID-19  ...                                              Italy\n",
       "142  COVID-19  ...  The Royal Melbourne Hospital, Melbourne, Austr...\n",
       "143  COVID-19  ...  The Royal Melbourne Hospital, Melbourne, Austr...\n",
       "144  COVID-19  ...                                                NaN\n",
       "145  COVID-19  ...                  Laniado Hospital, Netanya, Israel\n",
       "\n",
       "[146 rows x 4 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_data[['finding','view','modality','location']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "avQZiKZ0Sas4"
   },
   "source": [
    "### **Loading the image data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "id": "Gw1L6huXSBMe",
    "outputId": "93af937b-9b7f-4da0-836c-7b9b268970bf"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#List of files\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m path_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mpaths\u001b[49m\u001b[38;5;241m.\u001b[39mlist_images(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      3\u001b[0m X \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m Y \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'paths' is not defined"
     ]
    }
   ],
   "source": [
    "#List of files\n",
    "path_list = list(paths.list_images('Dataset'))\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "\n",
    "for path in path_list:\n",
    "    # Set Class label\n",
    "    y = path.split(os.path.sep)[-2]\n",
    "    # Grayscale the image and reshape\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (512, 512))\n",
    "\n",
    "    # update the data and labels lists, respectively\n",
    "    X.append(image)\n",
    "    Y.append(y)\n",
    "\n",
    "# Normalize images\n",
    "X = np.array(X) / 255.0\n",
    "Y = np.array(Y)\n",
    "\n",
    "print('Number of training images: ', len(X))\n",
    "# Plot example patient scan\n",
    "W = 8\n",
    "L = 1\n",
    "fig, axes = plt.subplots(L, W, figsize = (17,17))\n",
    "axes = axes.ravel() \n",
    "n = 138\n",
    "for i in np.arange(0, W * L):\n",
    "    index = np.random.randint(0, n)    \n",
    "    axes[i].imshow( X[index] )\n",
    "    axes[i].set_title(Y[index])\n",
    "\n",
    "\n",
    "#one-hot encoding on the labels\n",
    "lb = LabelBinarizer()\n",
    "Y = lb.fit_transform(Y)\n",
    "Y = tf.keras.utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bZY-SwmCdX3o"
   },
   "source": [
    "### **Splitting the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZMZGYzQWdgaK"
   },
   "outputs": [],
   "source": [
    "# split training and test data\n",
    "(X_train, x_test, Y_train, y_test) = train_test_split(X, Y,\n",
    "\ttest_size=0.20, stratify=Y, random_state=2019)\n",
    "\n",
    "(x_train, x_valid, y_train, y_valid) = train_test_split(X_train, Y_train,\n",
    "\ttest_size=0.20, stratify=Y_train, random_state=2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yIabWkNKh8Ty"
   },
   "source": [
    "### **Data Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xlm0eTuahE3m"
   },
   "outputs": [],
   "source": [
    "Datagen= tf.keras.preprocessing.image.ImageDataGenerator(featurewise_center=True,featurewise_std_normalization=True,\n",
    "                            rotation_range=20,width_shift_range=0.2,\n",
    "                            height_shift_range=0.2,horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RrE_uMSC0fbz"
   },
   "source": [
    "### **CNN Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hw5IRijzijJ1"
   },
   "outputs": [],
   "source": [
    "def Covid_model():\n",
    "    input_img = tf.keras.layers.Input(shape=(512, 512, 3))\n",
    "    baseModel = VGG16(weights=\"imagenet\", include_top=False,\n",
    "\t  input_tensor=tf.keras.layers.Input(shape=(512, 512, 3)))\n",
    "\n",
    "    # Make all pre-trained layers from VGG19 non-trainable \n",
    "    for layer in baseModel.layers[:-3]:\n",
    "        layer.trainable = False\n",
    "    x = baseModel.output\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=-1)(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=-1)(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=-1)(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = tf.keras.layers.Dropout(0.25)(x)\n",
    "    \n",
    "\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=-1)(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=-1)(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=-1)(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "  \n",
    "    \n",
    "    covid_model = tf.keras.models.Model(baseModel.input, x)\n",
    "    adagrad=tf.keras.optimizers.Adagrad(lr=0.001)\n",
    "    covid_model.compile(optimizer=adagrad, loss='binary_crossentropy',metrics=[\"accuracy\"])\n",
    "    return covid_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7eGmPU1c2PRC",
    "outputId": "8751f393-2d23-400a-83ac-37a7fd3172ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_30 (InputLayer)        [(None, 512, 512, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 512, 512, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 512, 512, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 256, 256, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 256, 256, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 128, 128, 256)     295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 128, 128, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 128, 128, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 64, 64, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 64, 64, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 64, 64, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_121 (Conv2D)          (None, 16, 16, 32)        147488    \n",
      "_________________________________________________________________\n",
      "batch_normalization_140 (Bat (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_122 (Conv2D)          (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_141 (Bat (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_123 (Conv2D)          (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_142 (Bat (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_61 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_124 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_143 (Bat (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_125 (Conv2D)          (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_144 (Bat (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_126 (Conv2D)          (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_145 (Bat (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_62 (MaxPooling (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_146 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 15,421,666\n",
      "Trainable params: 5,424,994\n",
      "Non-trainable params: 9,996,672\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:724: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 5s 454ms/step - loss: 1.1957 - accuracy: 0.5795 - val_loss: 0.6509 - val_accuracy: 0.8636\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 5s 424ms/step - loss: 0.9695 - accuracy: 0.6477 - val_loss: 0.6767 - val_accuracy: 0.5455\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 5s 421ms/step - loss: 0.6185 - accuracy: 0.7841 - val_loss: 0.6399 - val_accuracy: 0.7727\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 5s 419ms/step - loss: 0.9052 - accuracy: 0.6364 - val_loss: 0.6049 - val_accuracy: 0.6818\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 5s 418ms/step - loss: 0.7460 - accuracy: 0.7727 - val_loss: 0.5770 - val_accuracy: 0.6364\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 5s 426ms/step - loss: 0.6018 - accuracy: 0.7841 - val_loss: 0.5380 - val_accuracy: 0.5909\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 5s 421ms/step - loss: 0.2172 - accuracy: 0.8977 - val_loss: 0.4770 - val_accuracy: 0.7273\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 5s 420ms/step - loss: 0.3332 - accuracy: 0.8977 - val_loss: 0.4440 - val_accuracy: 0.7273\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 5s 419ms/step - loss: 0.6178 - accuracy: 0.7500 - val_loss: 0.5644 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 5s 426ms/step - loss: 0.3723 - accuracy: 0.8409 - val_loss: 0.3704 - val_accuracy: 0.9545\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 5s 443ms/step - loss: 0.3438 - accuracy: 0.8636 - val_loss: 0.3099 - val_accuracy: 0.9545\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 5s 421ms/step - loss: 0.3122 - accuracy: 0.8864 - val_loss: 0.2194 - val_accuracy: 0.9545\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 5s 425ms/step - loss: 0.3836 - accuracy: 0.8864 - val_loss: 0.1152 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 5s 417ms/step - loss: 0.3758 - accuracy: 0.8750 - val_loss: 0.1225 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 5s 420ms/step - loss: 0.2721 - accuracy: 0.8750 - val_loss: 0.0915 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 5s 418ms/step - loss: 0.2238 - accuracy: 0.8750 - val_loss: 0.1011 - val_accuracy: 0.9545\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 5s 421ms/step - loss: 0.3446 - accuracy: 0.8977 - val_loss: 0.2580 - val_accuracy: 0.9091\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 5s 421ms/step - loss: 0.1859 - accuracy: 0.9091 - val_loss: 0.1259 - val_accuracy: 0.9545\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 5s 421ms/step - loss: 0.0709 - accuracy: 0.9773 - val_loss: 0.1844 - val_accuracy: 0.9545\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 5s 419ms/step - loss: 0.3696 - accuracy: 0.8750 - val_loss: 0.3656 - val_accuracy: 0.8182\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 5s 422ms/step - loss: 0.2628 - accuracy: 0.9091 - val_loss: 0.3552 - val_accuracy: 0.8182\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 5s 420ms/step - loss: 0.2264 - accuracy: 0.9205 - val_loss: 0.2636 - val_accuracy: 0.9091\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.1946 - accuracy: 0.9318Restoring model weights from the end of the best epoch.\n",
      "11/11 [==============================] - 5s 429ms/step - loss: 0.1946 - accuracy: 0.9318 - val_loss: 0.3012 - val_accuracy: 0.9091\n",
      "Epoch 00023: early stopping\n"
     ]
    }
   ],
   "source": [
    " model= Covid_model()\n",
    " model.summary()\n",
    " early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)\n",
    "covid= model.fit_generator(Datagen.flow(x_train, y_train, batch_size=8),\n",
    "                      steps_per_epoch=len(x_train) / 8,\n",
    "                      validation_data=(x_valid, y_valid), epochs=100,callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jmQjGHtK0z3r"
   },
   "source": [
    "### **Performance Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "colab_type": "code",
    "id": "a_DbFlZ786k2",
    "outputId": "cb0c85d7-5e0d-4272-da67-67cb5ad18320"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.24419483542442322\n",
      "accuracy :  0.9285714030265808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       COVID       0.86      1.00      0.92        12\n",
      "      NORMAL       1.00      0.88      0.93        16\n",
      "\n",
      "    accuracy                           0.93        28\n",
      "   macro avg       0.93      0.94      0.93        28\n",
      "weighted avg       0.94      0.93      0.93        28\n",
      "\n",
      "accuracy: 0.9286\n",
      "sensitivity: 1.0000\n",
      "specificity: 0.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 15.0, 'Predicted label')"
      ]
     },
     "execution_count": 161,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict(x_test, batch_size=8)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "\n",
    "predicted_metrics = model.evaluate(x_test, y_test,\n",
    "                                  batch_size=8, verbose=0)\n",
    "for name, value in zip(model.metrics_names, predicted_metrics):\n",
    "  print(name, ': ', value)\n",
    "print(classification_report(y_pred, y_true,\n",
    "\ttarget_names=lb.classes_))\n",
    "cm = confusion_matrix(y_pred, y_true)\n",
    "total = sum(sum(cm))\n",
    "acc = (cm[0, 0] + cm[1, 1]) / total\n",
    "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "    \n",
    "print(\"accuracy: {:.4f}\".format(acc))\n",
    "print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
    "print(\"specificity: {:.4f}\".format(specificity))\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.title('Confusion matrix')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bVP40xBeiheL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "import sys\n",
    "from PIL import Image\n",
    "\n",
    "# Let's define a new Model that will take an image as input, and will output\n",
    "# intermediate representations for all layers in the previous model after\n",
    "# the first.\n",
    "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
    "# visualization model = Model(img_input, successive_outputs)\n",
    "visualization_model = tf.keras.models.Model(\n",
    "    inputs=model.input, outputs=successive_outputs\n",
    ")\n",
    "img = cv2.imread(\"/content/download.jpg\")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (512, 512))\n",
    "X = img_to_array(img)  # Numpy array with shape (512,512, 3)\n",
    "X = X.reshape((1,) + X.shape)  # Numpy array with shape (1, 512, 512, 3)\n",
    "# Rescale by 1/255 25\n",
    "X /= 255\n",
    "# Let's run our image through our network, thus obtaining all\n",
    "# intermediate representations for this image.\n",
    "successive_feature_maps = model.predict(X)\n",
    "print(successive_feature_maps)\n",
    "# These are the names of the Layers, so can have them as part of our plot\n",
    "layer_names = [layer.name for layer in model.layers]\n",
    "layer_names = [layer.name for layer in model.layers]\n",
    "# Now let's display our representations\n",
    "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
    "    if len(feature_map.shape) == 4:\n",
    "        # Just do this for the conv / maxpool Layers, not the fully-connected Layers\n",
    "        n_features = feature_map.shape[-1]  # number of features in feature map\n",
    "        size = feature_map.shape[1]\n",
    "        # We will tile our images in this matrix\n",
    "        display_grid = np.zeros((size, size * n_features))\n",
    "        for i in range(n_features):\n",
    "            x = feature_map[0, :, :, i]\n",
    "            x = x.mean()\n",
    "            X /= x.std()\n",
    "            X *= 64\n",
    "            X += 128\n",
    "            x = np.clip(x, 0, 255).astype(\"uint8\")\n",
    "            # We'll tile each filter into this big horizontal grid\n",
    "            display_grid[:, i * size : (i + 1) * size] = x\n",
    "        # Display the grid\n",
    "        scale = 20.0 / n_features\n",
    "        plt.figure(figsize=(scale * n_features, scale))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(display_grid, aspect=\"auto\", cmap=\"viridis\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Covid_diagnosis.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
